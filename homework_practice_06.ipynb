{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "homework-practice-06.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ph4nt0mm/Bash.im---proxy-for-Rambler/blob/master/homework_practice_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw3ocbbj9sD5",
        "colab_type": "text"
      },
      "source": [
        "# Машинное обучение, ФКН ВШЭ\n",
        "\n",
        "## Практическое задание 6. Разложение ошибки на смещение и разброс\n",
        "\n",
        "### Общая информация\n",
        "\n",
        "Дата выдачи: 23.11.2019\n",
        "\n",
        "Мягкий дедлайн: 8:00MSK 01.12.2019\n",
        "\n",
        "Жесткий дедлайн: 23:59MSK 02.12.2019\n",
        "\n",
        "### Оценивание и штрафы\n",
        "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
        "\n",
        "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке.\n",
        "\n",
        "### Формат сдачи\n",
        "Задания сдаются через систему anytask. Посылка должна содержать:\n",
        "* Ноутбук homework-practice-06-Username.ipynb\n",
        "\n",
        "Username — ваша фамилия и имя на латинице именно в таком порядке\n",
        "\n",
        "### О задании\n",
        "\n",
        "В этом задании вам предстоит воспользоваться возможностями bootstraping для оценки смещения и разброса алгоритмов машинного обучения. Делать мы это будем на данных boston:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yxKzmaO9sD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bTQDN_k9sD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_boston"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eODOm6vo9sEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boston = load_boston()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GilPQX_T9sEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = boston[\"data\"]\n",
        "y = boston[\"target\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSZzfRRY9sEH",
        "colab_type": "code",
        "outputId": "be389958-e786-4442-96df-417957c99831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((506, 13), (506,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DV3PeBp9sEL",
        "colab_type": "text"
      },
      "source": [
        "### Вычисление bias и variance с помощью бутстрапа\n",
        "На лекции была выведено следующая формула, показывающая, как можно представить ошибку алгоритма регрессии в виде суммы трех компонент:\n",
        "$$\n",
        "L(\\mu) = \n",
        "    \\mathbb{E}_{x, y}\\bigl[\\mathbb{E}_{X}\\bigl[ (y - \\mu(X)(x))^2 \\bigr]\\bigr] = \n",
        "$$\n",
        "$$\n",
        "    \\underbrace{\\mathbb{E}_{x, y}\\bigl[(y - \\mathbb{E}[y|x] )^2\\bigr]}_{\\text{шум}} + \\underbrace{\\mathbb{E}_{x}\\bigl[(\\mathbb{E}_{X}[\\mu(X)(x)] - \\mathbb{E}[y|x] )^2\\bigr]}_{\\text{смещение}} +\n",
        "    \\underbrace{\\mathbb{E}_{x}\\bigl[\\mathbb{E}_{X}\\bigl[(\\mu(X)(x) - \\mathbb{E}_{X}[\\mu(X)(x)] )^2\\bigr]\\bigr]}_{\\text{разброс}},\n",
        "$$\n",
        "* $\\mu(X)$ — алгоритм, обученный по выборке $X = \\{(x_1, y_1), \\dots (x_\\ell, y_\\ell)\\}$;\n",
        "* $\\mu(X)(x)$ — ответ алгоритма, обученного по выборке $X$, на объекте $x$;\n",
        "* $\\mathbb{E}_{X}$ — мат. ожидание по всем возможным выборкам;\n",
        "* $\\mathbb{E}_{X}[\\mu(X)(x)]$ — \"средний\" ответ алгоритма, обученного по всем возможным выборкам $X$, на объекте $x$.\n",
        "    \n",
        "С помощью этой формулы мы можем анализировать свойства алгоритма обучения модели $\\mu$, если зададим вероятностную модель порождения пар $p(x, y)$.\n",
        "\n",
        "В реальных задачах мы, конечно же, не знаем распределение на парах объект - правильный ответ. Однако у нас есть набор семплов из этого распределения (обучающую выборка), и мы можем использовать его, чтобы оценивать математические ожидания. Для оценки мат. ожиданий по выборкам мы будем пользоваться бутстрэпом - методом генерации \"новых\" выборок из одной с помощью выбора объектов с возвращением. Разберем несколько шагов на пути к оценке смещения и разброса.\n",
        "\n",
        "#### Приближенное вычисление интегралов\n",
        "На занятиях мы разбирали примеры аналитического вычисления смещения и разброса нескольких алгоритмов обучения. Для большинства моделей данных и алгоритмов обучения аналитически рассчитать математические ожидания в формулах не удастся. Однако мат. ожидания можно оценивать приближенно. Чтобы оценить математическое ожидание $\\mathbb{E}_{\\bar z} f(\\bar z)$ функции от многомерной случайной величины $\\bar z = (z_1, \\dots, z_d)$, $\\bar z \\sim p(\\bar z)$, можно сгенерировать выборку из распределения $p(\\bar z)$ и усреднить значение функции на элементах этой выборки:\n",
        "$$\\mathbb{E}_{\\bar z} f(z) = \\int f(\\bar z) p(\\bar z) d \\bar z \\approx \\frac 1 m \\sum_{i=1}^m f(\\bar z_i), \\, \\bar z_i \\sim p(\\bar z), i = 1, \\dots, m.$$\n",
        "\n",
        "Например, оценим $\\mathbb{E}_z z^2,$ $z \\sim \\mathcal{N}(\\mu=5, \\sigma=3)$ (из теории вероятностей мы знаем, что\n",
        "$\\mathbb{E}_z z^2 = \\sigma^2 + \\mu^2 = 34$):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYUeq1y39sEM",
        "colab_type": "code",
        "outputId": "5f672f6d-df38-43d0-e6f4-99c57256fc08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = np.random.normal(loc=5, scale=3, size=1000)\n",
        "(z**2).mean()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36.41260335879168"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3e9jeZH9sEP",
        "colab_type": "text"
      },
      "source": [
        "#### Оценивание $\\mathbb{E}_{x, y}$\n",
        "Оценить мат. ожидания по $x$ и по $x, y$, встречающиеся во всех трех компонентах разложения, несложно, потому что у нас есть выборка объектов из распределения данных $p(x, y)$:\n",
        "$$ \\mathbb{E}_{x} f(x) \\approx \\frac 1 N \\sum_{i=1}^N f(x_i), \\quad\n",
        "\\mathbb{E}_{x, y} f(x, y) \\approx \\frac 1 N \\sum_{i=1}^N f(x_i, y_i),$$\n",
        "где $N$ - число объектов в выборке, $\\{(x_i, y_i)\\}_{i=1}^N$ - сама выборка. \n",
        "\n",
        "#### Оценивание $\\mathbb{E}_X$ с помощью бутстрапа\n",
        "Чтобы оценить мат. ожидание по $X$, нам понадобится выборка из выборок:\n",
        "$$\\mathbb{E}_X f(X) \\approx \\frac 1 s \\sum_{j=1}^s f(X_j),$$\n",
        "где $X_j$ - $j$-я выборка. Чтобы их получить, мы можем воспользоваться бутстрапом - методом генерации выборок на основе выбора объектов с возвращением. Чтобы составить одну выборку, будем $N$ раз выбирать индекс объекта $i \\sim \\text{Uniform}(1 \\dots N)$ и добавлять $i$-ю пару (объект, целевая переменная) в выборку. В результате в каждой выборке могут появиться повторяющиеся объекты, а какие-то объекты могут вовсе не войти в некоторые выборки.\n",
        "\n",
        "#### Итоговый алгоритм оценки смещения и разброса алгоритма $a$\n",
        "1. Сгенерировать $s$ выборок $X_j$ методом бутстрапа.\n",
        "1. На каждой выборке $X_j$ обучить алгоритм $a_j$.\n",
        "1. Для каждой выборки $X_j$ определить множество объектов $T_j$, не вошедших в нее (out-of-bag). Вычислить предсказания алгоритма $a_j$ на объектах $T_j$. \n",
        "\n",
        "Поскольку у нас есть только один ответ для каждого объекта, мы будем считать шум равным 0, а $\\mathbb{E}[y|x]$ равным имеющемуся правильному ответу для объекта $x$. \n",
        "\n",
        "Итоговые оценки:\n",
        "* Смещение: для одного объекта - квадрат разности среднего предсказания и правильного ответа. Среднее предсказание берется только по тем алгоритмам $a_j$, для которых этот объект входил в out-of-bag выборку $T_j$. Для получения общего смещения выполнить усреденение смещений по объектам.\n",
        "* Разброс: для одного объекта - выборочная дисперсия предсказаний алгоритмов $a_j$, для которых этот объект входил в out-of-bag выборку $T_j$. Для получения общего разброса выполнить усреденение разбросов по объектам.\n",
        "* Ошибка $L$: усреднить квадраты разностей предсказания и правильного ответа по всем выполненным предсказаниям для всех объектов.\n",
        "\n",
        "В результате должно получиться, что ошибка приблизительно равна сумме смещения и разброса!\n",
        "\n",
        "Алгоритм также вкратце описан по [ссылке](https://web.engr.oregonstate.edu/~tgd/classes/534/slides/part9.pdf) (слайды 19-21).\n",
        "\n",
        "__1. (3 балла)__\n",
        "\n",
        "Реализуйте описанный алгоритм. Обратите внимание, что если объект не вошел ни в одну из out-of-bag выборок, учитывать его в вычислении итоговых величин не нужно. Как обычно, разрешается использовать только один цикл - по выборкам (от 0 до num_runs-1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDdINA7F9sEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_biase_variance(regressor, X, y, num_runs=1000):\n",
        "    \"\"\"\n",
        "    :param regressor: sklearn estimator with fit(...) and predict(...) method\n",
        "    :param X: numpy-array representing training set ob objects, shape [n_obj, n_feat]\n",
        "    :param y: numpy-array representing target for training objects, shape [n_obj]\n",
        "    :param num_runs: int, number of samples (s in the description of the algorithm)\n",
        "    \n",
        "    :returns: bias (float), variance (float), error (float) \n",
        "    each value is computed using bootstrap\n",
        "    \"\"\"\n",
        "           \n",
        "    ### your code here\n",
        "    \n",
        "    X = pd.DataFrame(data=X)\n",
        "    y = pd.DataFrame(data=y)\n",
        "    \n",
        "    X_res = pd.DataFrame(data=X).drop(columns=pd.DataFrame(data=X).columns)\n",
        "    \n",
        "    X_res[\"count\"] = 0\n",
        "    X_res[\"square\"] = 0\n",
        "    X_res[\"bias\"] = 0\n",
        "    X_res[\"err\"] = 0\n",
        "    X[\"target\"] = y\n",
        "    \n",
        "    for i in range(0, num_runs):\n",
        "        X_new = X.sample(frac=0.99, replace=True)\n",
        "        regressor.fit(X_new.drop(columns=['target']), X_new[\"target\"])\n",
        "\n",
        "        X_res[\"count\"].iloc[np.array(X.drop(X_new.index).index)] += 1\n",
        "        X_res[\"bias\"].iloc[np.array(X.drop(X_new.index).index)] += regressor.predict(X.drop(X_new.index).drop(columns=['target']))\n",
        "        X_res[\"square\"].iloc[np.array(X.drop(X_new.index).index)] += regressor.predict(X.drop(X_new.index).drop(columns=['target'])) ** 2\n",
        "        X_res[\"err\"].iloc[np.array(X.drop(X_new.index).index)] += (regressor.predict(X.drop(X_new.index).drop(columns=['target'])) - \n",
        "                                                                   X.drop(X_new.index)['target']) ** 2\n",
        "\n",
        "    \n",
        "    return((np.mean(np.array(((X_res[\"bias\"] / X_res[\"count\"]) - y.T) ** 2))),\n",
        "            (np.mean(np.array((X_res[\"square\"] / X_res[\"count\"]) - (X_res[\"bias\"] / X_res[\"count\"]) ** 2))),\n",
        "           (np.mean(np.array((X_res[\"err\"] / X_res[\"count\"])))))\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPFCerHP9sER",
        "colab_type": "text"
      },
      "source": [
        "__2. (0 баллов)__\n",
        "\n",
        "Оцените смещение, разброс и ошибку для трех алгоритмов с гиперпараметрами по умолчанию: линейная регрессия, решающее дерево, случайный лес."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "757ilSiI9sES",
        "colab_type": "code",
        "outputId": "fe1c91d7-f261-44d3-88a7-fbac773eb9e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "### your code here\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "bias, variance, error = compute_biase_variance(LinearRegression(), X, y)\n",
        "print(\"Bias, variance and error for linear regression: \", bias, variance, error)\n",
        "\n",
        "bias, variance, error = compute_biase_variance(DecisionTreeRegressor(), X, y)\n",
        "print(\"Bias, variance and error for Dec tree:\", bias, variance, error)\n",
        "\n",
        "bias, variance, error = compute_biase_variance(RandomForestRegressor(), X, y)\n",
        "print(\"Bias, variance and error for Rand tree:\", bias, variance, error)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bias, variance and error for linear regression:  23.745713108780166 0.9456297034190881 24.69134281219933\n",
            "Bias, variance and error for Dec tree: 10.140867699313398 13.018251552972187 23.15911925228559\n",
            "Bias, variance and error for Rand tree: 10.784737421318463 3.4078202094918955 14.192557630810336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZIiWaVA9sEV",
        "colab_type": "text"
      },
      "source": [
        "__3. (1 балл)__\n",
        "Проанализируйте полученный результат. Согласуются ли полученные результаты с теми, что мы обсуждали на семинарах (с комментарием)?\n",
        "\n",
        "__Your answer here:__\n",
        "Как и ожидалось, разброс и смещение кореллируют друг с другом и в сумме дают среднюю ошибку моделе. Можем подтвердить приближенность шума к 0 тк сумма разброса и смещения очень близка к средней ошибке\n",
        "\n",
        "Заметим, что смещение у регрессии и дерева больше, чем у леса почти в 2 раза. Интересное наблюдение.\n",
        "\n",
        "__3. (1 балл)__\n",
        "Вспомните обсуждение с лекции о том, во сколько раз в теории бутстрап уменьшает разброс базового алгоритма. Выполняется ли это в ваших экспериментах? Если нет, поясните, почему.\n",
        "\n",
        "__Your answer here:__\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvRnR_fG9sEV",
        "colab_type": "text"
      },
      "source": [
        "### Визуализация предсказаний базовых алгоритмов бэггинга\n",
        "\n",
        "В материалах лекций можно найти изображение, похожее на мишень - визуализация алгоритмов с разным смещением и разным разбросом. В центре \"мишени\" - правильный ответ, а \"попадания\" - предсказания алгоритмов, обученных по разным выборкам. Построим похожее изображение на наших данных для трех алгоритмов. Наши \"мишени\" будут одномерными, потому что мы решаем задачу одномерной регрессии.\n",
        "\n",
        "__4. (2 балла)__\n",
        "\n",
        "Реализуйте фукнцию plot_predictions. Она должна выполнять следующие действия:\n",
        "1. Случайно выбрать num_test_objects пар объект-целевая переменная из выборки X, y. Получится две выборки: маленькая X_test, y_test (выбранные тестовые объекты) и X_train, y_train (остальные объекты).\n",
        "\n",
        "\n",
        "1. Сгенерировать num_runs выборок методом бутстарапа из X_train, y_train. На каждой выборке обучить алгоритм regressor и сделать предсказания для X_test.\n",
        "\n",
        "\n",
        "1. Нарисовать scatter-график. По оси абсцисс - объекты тестовой выборки (номера от 0 до num_test_objects-1), по оси ординат - предсказания. В итоге получится num_test_objects столбиков с точками. Для каждого тестового объекта надо отметить одним цветом все предсказания для него, а также черным цветом отметить правильный ответ.\n",
        "1. Подпишите оси и название графика (аргумент title)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxP-sRY99sEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def plot_predictions(regressor, X, y, num_runs=100, num_test_objects=30, title=\"\"):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=num_test_objects, random_state=42)\n",
        "    \n",
        "    X_train = pd.DataFrame(data=X_train)\n",
        "    y_train = pd.DataFrame(data=y_train)\n",
        "    X_train[\"target\"] = y_train\n",
        "    \n",
        "    for i in range(0, num_runs):\n",
        "        X_new = X_train.sample(frac=0.9, replace=True)\n",
        "        \n",
        "        y_new = X_new[\"target\"]\n",
        "        X_new = X_new.drop(columns=[\"target\"])\n",
        "        \n",
        "        regressor.fit(X_new, y_new)\n",
        "        regressor.predict(X_test)\n",
        "        plt.scatter(range(len(y_test)), regressor.predict(X_test), c = range(len(y_test)))\n",
        "        \n",
        "    \n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Object number\")\n",
        "    plt.ylabel(\"Predictions\")\n",
        "    plt.scatter(range(len(y_test)), y_test, c = 'black')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aihW5luf9sEY",
        "colab_type": "text"
      },
      "source": [
        "__5. (0 баллов)__\n",
        "\n",
        "Нарисуйте графики для линейной регрессии, решающего дерева и случайного леса. Нарисуйте три графика в строчку (это можно сделать с помощью plt.subplot) с одинаковой осью ординат (это важно для понимания масштаба разброса у разных алгоритмов):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVBmHMsp9sEZ",
        "colab_type": "code",
        "outputId": "373c4335-7061-45b2-816e-733f9d873732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        }
      },
      "source": [
        "### your code here\n",
        "import random\n",
        "plt.figure(figsize=(17, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "plot_predictions(LinearRegression(), X, y, num_runs=100, title=\"Linear Regression\")\n",
        "plt.ylim((0, 40))\n",
        "plt.subplot(1, 3, 2)\n",
        "plot_predictions(DecisionTreeRegressor(), X, y, num_runs=100, title=\"Decision Tree\")\n",
        "plt.ylim((0, 35))\n",
        "plt.subplot(1, 3, 3)\n",
        "plot_predictions(RandomForestRegressor(), X, y, num_runs=100, title=\"Random Forest\")\n",
        "plt.ylim((0, 50))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a3facbfafef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplot_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_runs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Linear Regression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAAFpCAYAAADk2FEuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 1224x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx7cZ89q9sEb",
        "colab_type": "text"
      },
      "source": [
        "__6. (1 балл)__\n",
        "\n",
        "Для каждого графика прокомментируйте, как он характеризует смещение и разброс соответствующего алгоритма. \n",
        "\n",
        "__Your answer here:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDZ1xcPB9sEc",
        "colab_type": "text"
      },
      "source": [
        "### Изменение bias и variance при изменении гиперпараметров"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMt05W6J9sEc",
        "colab_type": "text"
      },
      "source": [
        "__7. (0 баллов)__\n",
        "\n",
        "Постройте графики зависимости смещения и разброса от гиперпараметров решающего дерева max_depth (от 1 до 10) и max_features (от 1 до X.shape[1]):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydNXsrcQ9sEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### your code here\n",
        "for i in range(1, 11)\n",
        "bias, variance, error = compute_biase_variance(DecisionTreeRegressor(max_depth=i), X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB8y8EZW9sEg",
        "colab_type": "text"
      },
      "source": [
        "__8. (0 баллов)__\n",
        "\n",
        "Постройте графики зависимости смещения и разброса от n_estimators (по сетке 2**np.arange(1, 10)) для случайного леса и градиентного бустинга:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny5s1I1c9sEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i7HngPA9sEk",
        "colab_type": "text"
      },
      "source": [
        "__3. (2 балла)__\n",
        "\n",
        "Прокомментируйте графики (всего 4 графика): почему они имеют такой вид.\n",
        "\n",
        "__Your answer here:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSiapZXEAzCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0vwnNdBA1Kh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "8b8b9ad8-8050-431a-f5d9-eceed82c9139"
      },
      "source": [
        "mx_depth = range(1, 10)\n",
        "mx_features = range(1, X.shape[1])\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "biases = list()\n",
        "variances = list()\n",
        "\n",
        "for depth in mx_depth:\n",
        "    regressor = DecisionTreeRegressor(max_depth=depth)\n",
        "    bias, variance, _ = compute_biase_variance(regressor, X, y, num_runs=400)\n",
        "    biases.append(bias)\n",
        "    variances.append(variance)\n",
        "\n",
        "plt.subplot2grid((1, 2), (0, 0))\n",
        "plt.plot(mx_depth, np.array(biases), '-', c='r')\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.ylabel(\"bias\")\n",
        "plt.grid(True)\n",
        "plt.subplot2grid((1, 2), (0, 1))\n",
        "plt.plot(mx_depth, np.array(variances), '-', c='b')\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.ylabel(\"variance\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-950af5bd16d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmx_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_biase_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_runs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbiases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeRegressor' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYMUS1HbA25m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}